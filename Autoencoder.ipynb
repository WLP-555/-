{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_epoch = 100\n",
    "\n",
    "# Parameters for mne dataset\n",
    "channels_num = 61\n",
    "encoding_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from data/resting_state/zavrin_open_eyes_eeg_15021500.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 301999  =      0.000 ...   301.999 secs...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(302000, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = mne.io.read_raw_brainvision(\"data/resting_state/zavrin_open_eyes_eeg_15021500.vhdr\", preload=True)\n",
    "data = raw.get_data().T\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 61)                0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 32)                1984      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 61)                2013      \n",
      "=================================================================\n",
      "Total params: 3,997\n",
      "Trainable params: 3,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build autoencoder model\n",
    "input_ = Input(shape=(channels_num,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_)\n",
    "\n",
    "input_encoded = Input(shape=(encoding_dim,))\n",
    "decoded = Dense(channels_num, activation='sigmoid')(input_encoded)\n",
    "\n",
    "encoder = Model(input_, encoded, name=\"encoder\")\n",
    "decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "\n",
    "autoencoder = Model(input_, decoder(encoder(input_)), name=\"autoencoder\")\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211400, 61)\n",
      "(90600, 61)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, _, _ = train_test_split(data, data, test_size=0.3)\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211400, 61)\n",
      "(90600, 61)\n"
     ]
    }
   ],
   "source": [
    "X_train_noise = X_train + 0.3 * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
    "X_test_noise = X_test + 0.3 * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
    "X_train_noise = np.clip(X_train_noise, 0., 1.)\n",
    "X_test_noise = np.clip(X_test_noise, 0., 1.)\n",
    "print(X_train_noise.shape)\n",
    "print(X_test_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 211400 samples, validate on 90600 samples\n",
      "Epoch 1/1\n",
      "211400/211400 [==============================] - 8s 40us/step - loss: 0.0103 - val_loss: -1.9424e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1203c8a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "autoencoder.fit(X_train_noise, X_train, verbose=1,\n",
    "                validation_data=(X_test_noise, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сжатие в формат pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import tempfile\n",
    "import keras.models\n",
    "import pickle\n",
    "import mne as mn\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_keras_picklable():\n",
    "    def __getstate__(self):\n",
    "        model_str = \"\"\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            keras.models.save_model(self, fd.name, overwrite=True)\n",
    "            model_str = fd.read()\n",
    "        d = { 'model_str': model_str }\n",
    "        return d\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            fd.write(state['model_str'])\n",
    "            fd.flush()\n",
    "            model = keras.models.load_model(fd.name)\n",
    "        self.__dict__ = model.__dict__\n",
    "\n",
    "\n",
    "    cls = keras.models.Model\n",
    "    cls.__getstate__ = __getstate__\n",
    "    cls.__setstate__ = __setstate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_keras_picklable()\n",
    "pickle.dump(encoder, open(\"encoder.p\", \"wb\"))\n",
    "pickle.dump(decoder, open(\"decoder.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_encoder = pickle.load(open(\"encoder.p\", \"rb\"))\n",
    "load_decoder = pickle.load(open(\"decoder.p\", \"rb\"))\n",
    "x_reduce = load_encoder.predict(x_test)\n",
    "alpha = x_reduce.shape[1] / 64\n",
    "x_pred = load_decoder.predict(x_reduce)\n",
    "mse = mean_squared_error(x_train, x_test)\n",
    "score = (1 + mse) * alpha\n",
    "if (alpha > 0.9): \n",
    "    score = 100000 #infty\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
